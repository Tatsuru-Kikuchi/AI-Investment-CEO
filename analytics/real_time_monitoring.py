#!/usr/bin/env python3\n\"\"\"\nReal-Time AI Implementation Impact Monitoring System\n\nTracks mechanism-specific productivity effects across client implementations,\nproviding live dashboards and early warning systems for optimization.\n\nAuthor: Tatsuru Kikuchi\nDate: August 2025\n\"\"\"\n\nimport asyncio\nimport json\nimport logging\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional, Tuple\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\nimport sqlite3\nimport aiohttp\nfrom fastapi import FastAPI, BackgroundTasks\nfrom fastapi.middleware.cors import CORSMiddleware\nimport uvicorn\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass MechanismType(Enum):\n    COST_REDUCTION = \"cost_reduction\"\n    REVENUE_ENHANCEMENT = \"revenue_enhancement\"\n    INNOVATION_ACCELERATION = \"innovation_acceleration\"\n\nclass ImplementationStage(Enum):\n    PLANNING = \"planning\"\n    PILOT = \"pilot\"\n    DEPLOYMENT = \"deployment\"\n    OPTIMIZATION = \"optimization\"\n    MAINTENANCE = \"maintenance\"\n\n@dataclass\nclass FirmProfile:\n    \"\"\"Client firm characteristics for mechanism effectiveness prediction\"\"\"\n    firm_id: str\n    name: str\n    size: str  # micro, small, medium, large\n    industry: str\n    employees: int\n    annual_revenue: float\n    ceo_age: int\n    ceo_gender: str\n    tech_readiness: float  # 0-1 scale\n    baseline_productivity: float\n    \n@dataclass\nclass MechanismImplementation:\n    \"\"\"Mechanism-specific implementation tracking\"\"\"\n    implementation_id: str\n    firm_id: str\n    mechanism_type: MechanismType\n    start_date: datetime\n    stage: ImplementationStage\n    investment_amount: float\n    expected_effect: float\n    actual_effect: Optional[float] = None\n    milestone_completion: float = 0.0  # 0-1 scale\n    risk_score: float = 0.0  # 0-1 scale\n    \n@dataclass\nclass ProductivityMeasurement:\n    \"\"\"Real-time productivity tracking\"\"\"\n    measurement_id: str\n    firm_id: str\n    implementation_id: str\n    measurement_date: datetime\n    productivity_growth: float\n    cost_savings: Optional[float] = None\n    revenue_increase: Optional[float] = None\n    innovation_metrics: Optional[float] = None\n    confidence_interval: Tuple[float, float] = (0.0, 0.0)\n    \n@dataclass\nclass AlertMetric:\n    \"\"\"Early warning system alerts\"\"\"\n    alert_id: str\n    firm_id: str\n    implementation_id: str\n    alert_type: str  # performance, timeline, risk\n    severity: str  # low, medium, high, critical\n    message: str\n    created_at: datetime\n    resolved: bool = False\n\nclass RealTimeMonitoringSystem:\n    \"\"\"\n    Comprehensive real-time monitoring system for AI implementation tracking\n    \"\"\"\n    \n    def __init__(self, db_path: str = \"monitoring.db\"):\n        self.db_path = db_path\n        self.app = FastAPI(title=\"AI Implementation Monitor\")\n        self.setup_database()\n        self.setup_api_routes()\n        self.setup_cors()\n        \n        # Mechanism effectiveness multipliers from research\n        self.size_multipliers = {\n            'micro': {'cost': 0.6, 'revenue': 0.8, 'innovation': 1.2},\n            'small': {'cost': 0.8, 'revenue': 0.9, 'innovation': 1.1},\n            'medium': {'cost': 1.0, 'revenue': 1.1, 'innovation': 1.0},\n            'large': {'cost': 1.4, 'revenue': 1.2, 'innovation': 0.9}\n        }\n        \n        self.industry_multipliers = {\n            'technology': 1.3, 'finance': 1.2, 'manufacturing': 1.1,\n            'services': 1.0, 'healthcare': 0.9, 'retail': 0.8\n        }\n        \n        # Base mechanism effects from research (2.4% total quarterly)\n        self.base_effects = {\n            MechanismType.COST_REDUCTION: 0.024 * 0.40,      # 40% of total\n            MechanismType.REVENUE_ENHANCEMENT: 0.024 * 0.35,  # 35% of total\n            MechanismType.INNOVATION_ACCELERATION: 0.024 * 0.25 # 25% of total\n        }\n        \n    def setup_database(self):\n        \"\"\"Initialize SQLite database for monitoring data\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        cursor = conn.cursor()\n        \n        # Create all necessary tables\n        self._create_tables(cursor)\n        conn.commit()\n        conn.close()\n        logger.info(\"Database initialized successfully\")\n        \n    def _create_tables(self, cursor):\n        \"\"\"Create database tables\"\"\"\n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS firms (\n                firm_id TEXT PRIMARY KEY,\n                name TEXT NOT NULL,\n                size TEXT NOT NULL,\n                industry TEXT NOT NULL,\n                employees INTEGER,\n                annual_revenue REAL,\n                ceo_age INTEGER,\n                ceo_gender TEXT,\n                tech_readiness REAL,\n                baseline_productivity REAL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        \"\"\")\n        \n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS implementations (\n                implementation_id TEXT PRIMARY KEY,\n                firm_id TEXT NOT NULL,\n                mechanism_type TEXT NOT NULL,\n                start_date TIMESTAMP,\n                stage TEXT NOT NULL,\n                investment_amount REAL,\n                expected_effect REAL,\n                actual_effect REAL,\n                milestone_completion REAL DEFAULT 0,\n                risk_score REAL DEFAULT 0,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (firm_id) REFERENCES firms (firm_id)\n            )\n        \"\"\")\n        \n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS measurements (\n                measurement_id TEXT PRIMARY KEY,\n                firm_id TEXT NOT NULL,\n                implementation_id TEXT NOT NULL,\n                measurement_date TIMESTAMP,\n                productivity_growth REAL,\n                cost_savings REAL,\n                revenue_increase REAL,\n                innovation_metrics REAL,\n                confidence_lower REAL,\n                confidence_upper REAL,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (firm_id) REFERENCES firms (firm_id),\n                FOREIGN KEY (implementation_id) REFERENCES implementations (implementation_id)\n            )\n        \"\"\")\n        \n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS alerts (\n                alert_id TEXT PRIMARY KEY,\n                firm_id TEXT NOT NULL,\n                implementation_id TEXT,\n                alert_type TEXT NOT NULL,\n                severity TEXT NOT NULL,\n                message TEXT NOT NULL,\n                resolved BOOLEAN DEFAULT FALSE,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (firm_id) REFERENCES firms (firm_id)\n            )\n        \"\"\")\n        \n    def setup_cors(self):\n        \"\"\"Setup CORS for web dashboard access\"\"\"\n        self.app.add_middleware(\n            CORSMiddleware,\n            allow_origins=[\"*\"],\n            allow_credentials=True,\n            allow_methods=[\"*\"],\n            allow_headers=[\"*\"],\n        )\n        \n    def predict_mechanism_effect(self, firm: FirmProfile, mechanism: MechanismType) -> float:\n        \"\"\"Predict mechanism-specific effect for a firm based on research\"\"\"\n        base_effect = self.base_effects[mechanism]\n        \n        # Apply size multiplier\n        mechanism_key = mechanism.value.split('_')[0]  # cost, revenue, innovation\n        size_multiplier = self.size_multipliers[firm.size][mechanism_key]\n        \n        # Apply industry multiplier\n        industry_multiplier = self.industry_multipliers.get(firm.industry, 1.0)\n        \n        # CEO demographics adjustment\n        demo_multiplier = 1.0\n        if firm.ceo_age < 45:\n            demo_multiplier *= 1.1\n        if firm.ceo_gender == 'female':\n            demo_multiplier *= 1.05\n            \n        # Technology readiness adjustment\n        tech_multiplier = 0.7 + 0.6 * firm.tech_readiness\n        \n        final_effect = (base_effect * size_multiplier * industry_multiplier * \n                       demo_multiplier * tech_multiplier)\n        \n        return final_effect\n    \n    def calculate_risk_score(self, implementation: MechanismImplementation, \n                           recent_measurements: List[ProductivityMeasurement]) -> float:\n        \"\"\"Calculate implementation risk score based on performance\"\"\"\n        risk_factors = []\n        \n        # Timeline risk\n        days_since_start = (datetime.now() - implementation.start_date).days\n        expected_days_by_stage = {\n            ImplementationStage.PLANNING: 30,\n            ImplementationStage.PILOT: 90,\n            ImplementationStage.DEPLOYMENT: 180,\n            ImplementationStage.OPTIMIZATION: 270\n        }\n        \n        if days_since_start > expected_days_by_stage.get(implementation.stage, 365):\n            risk_factors.append(0.3)  # Timeline overrun\n            \n        # Performance risk\n        if recent_measurements:\n            latest_measurement = recent_measurements[-1]\n            performance_ratio = latest_measurement.productivity_growth / implementation.expected_effect\n            if performance_ratio < 0.5:  # Less than 50% of expected\n                risk_factors.append(0.4)\n            elif performance_ratio < 0.8:  # Less than 80% of expected\n                risk_factors.append(0.2)\n                \n        # Milestone risk\n        expected_completion = min(days_since_start / 180, 1.0)  # Expected completion over 6 months\n        if implementation.milestone_completion < expected_completion * 0.7:\n            risk_factors.append(0.3)\n            \n        return min(sum(risk_factors), 1.0)\n    \n    def generate_alerts(self, firm_id: str, implementation: MechanismImplementation, \n                       measurements: List[ProductivityMeasurement]) -> List[AlertMetric]:\n        \"\"\"Generate early warning alerts based on implementation status\"\"\"\n        alerts = []\n        \n        # Performance alert\n        if measurements:\n            latest = measurements[-1]\n            if latest.productivity_growth < implementation.expected_effect * 0.5:\n                alerts.append(AlertMetric(\n                    alert_id=f\"perf_{implementation.implementation_id}_{datetime.now().timestamp()}\",\n                    firm_id=firm_id,\n                    implementation_id=implementation.implementation_id,\n                    alert_type=\"performance\",\n                    severity=\"high\",\n                    message=f\"Productivity growth ({latest.productivity_growth:.1%}) significantly below target ({implementation.expected_effect:.1%})\",\n                    created_at=datetime.now()\n                ))\n                \n        # Timeline alert\n        days_since_start = (datetime.now() - implementation.start_date).days\n        if days_since_start > 180 and implementation.stage in [ImplementationStage.PLANNING, ImplementationStage.PILOT]:\n            alerts.append(AlertMetric(\n                alert_id=f\"time_{implementation.implementation_id}_{datetime.now().timestamp()}\",\n                firm_id=firm_id,\n                implementation_id=implementation.implementation_id,\n                alert_type=\"timeline\",\n                severity=\"medium\",\n                message=f\"Implementation delayed: {days_since_start} days in {implementation.stage.value} stage\",\n                created_at=datetime.now()\n            ))\n            \n        # Risk alert\n        if implementation.risk_score > 0.7:\n            alerts.append(AlertMetric(\n                alert_id=f\"risk_{implementation.implementation_id}_{datetime.now().timestamp()}\",\n                firm_id=firm_id,\n                implementation_id=implementation.implementation_id,\n                alert_type=\"risk\",\n                severity=\"critical\",\n                message=f\"High risk score ({implementation.risk_score:.1%}) - immediate intervention recommended\",\n                created_at=datetime.now()\n            ))\n            \n        return alerts\n    \n    def setup_api_routes(self):\n        \"\"\"Setup FastAPI routes for dashboard access\"\"\"\n        \n        @self.app.get(\"/\")\n        async def root():\n            return {\"message\": \"AI Implementation Monitoring System\", \"status\": \"operational\"}\n        \n        @self.app.get(\"/health\")\n        async def health_check():\n            \"\"\"System health check endpoint\"\"\"\n            conn = sqlite3.connect(self.db_path)\n            cursor = conn.cursor()\n            \n            # Check database connectivity\n            try:\n                cursor.execute(\"SELECT COUNT(*) FROM firms\")\n                firm_count = cursor.fetchone()[0]\n                \n                cursor.execute(\"SELECT COUNT(*) FROM implementations\")\n                impl_count = cursor.fetchone()[0]\n                \n                cursor.execute(\"SELECT COUNT(*) FROM measurements\")\n                measurement_count = cursor.fetchone()[0]\n                \n                conn.close()\n                \n                return {\n                    \"status\": \"healthy\",\n                    \"timestamp\": datetime.now().isoformat(),\n                    \"database\": {\n                        \"firms\": firm_count,\n                        \"implementations\": impl_count,\n                        \"measurements\": measurement_count\n                    }\n                }\n            except Exception as e:\n                conn.close()\n                logger.error(f\"Health check failed: {e}\")\n                return {\"status\": \"unhealthy\", \"error\": str(e)}\n        \n        @self.app.get(\"/dashboard/global\")\n        async def get_global_dashboard():\n            \"\"\"Get global aggregated dashboard data\"\"\"\n            conn = sqlite3.connect(self.db_path)\n            \n            try:\n                # Global metrics\n                cursor = conn.cursor()\n                \n                # Total firms and implementations\n                cursor.execute(\"SELECT COUNT(*) FROM firms\")\n                total_firms = cursor.fetchone()[0]\n                \n                cursor.execute(\"SELECT COUNT(*) FROM implementations\")\n                total_implementations = cursor.fetchone()[0]\n                \n                # Average productivity improvement\n                cursor.execute(\"\"\"\n                    SELECT AVG(productivity_growth) \n                    FROM measurements \n                    WHERE measurement_date >= date('now', '-30 days')\n                \"\"\")\n                avg_productivity = cursor.fetchone()[0] or 0\n                \n                # Success rate (implementations meeting targets)\n                cursor.execute(\"\"\"\n                    SELECT \n                        COUNT(CASE WHEN m.productivity_growth >= i.expected_effect * 0.8 THEN 1 END) * 1.0 / COUNT(*)\n                    FROM measurements m\n                    JOIN implementations i ON m.implementation_id = i.implementation_id\n                    WHERE m.measurement_date >= date('now', '-30 days')\n                \"\"\")\n                success_rate = cursor.fetchone()[0] or 0\n                \n                # Recent alerts\n                cursor.execute(\"\"\"\n                    SELECT alert_type, severity, COUNT(*)\n                    FROM alerts \n                    WHERE resolved = FALSE AND created_at >= date('now', '-7 days')\n                    GROUP BY alert_type, severity\n                \"\"\")\n                alert_summary = cursor.fetchall()\n                \n                conn.close()\n                \n                return {\n                    \"global_metrics\": {\n                        \"total_firms\": total_firms,\n                        \"total_implementations\": total_implementations,\n                        \"avg_productivity_improvement\": avg_productivity,\n                        \"success_rate\": success_rate\n                    },\n                    \"alert_summary\": [\n                        {\"type\": row[0], \"severity\": row[1], \"count\": row[2]} \n                        for row in alert_summary\n                    ],\n                    \"timestamp\": datetime.now().isoformat()\n                }\n                \n            except Exception as e:\n                conn.close()\n                logger.error(f\"Global dashboard error: {e}\")\n                return {\"error\": str(e)}\n    \n    async def check_and_generate_alerts(self, firm_id: str, implementation_id: str):\n        \"\"\"Check implementation status and generate alerts if needed\"\"\"\n        conn = sqlite3.connect(self.db_path)\n        \n        try:\n            # Get implementation details\n            impl_df = pd.read_sql(\n                \"SELECT * FROM implementations WHERE implementation_id = ?\",\n                conn, params=(implementation_id,)\n            )\n            \n            if impl_df.empty:\n                return\n                \n            impl_row = impl_df.iloc[0]\n            implementation = MechanismImplementation(\n                implementation_id=impl_row['implementation_id'],\n                firm_id=impl_row['firm_id'],\n                mechanism_type=MechanismType(impl_row['mechanism_type']),\n                start_date=datetime.fromisoformat(impl_row['start_date']),\n                stage=ImplementationStage(impl_row['stage']),\n                investment_amount=impl_row['investment_amount'],\n                expected_effect=impl_row['expected_effect'],\n                actual_effect=impl_row['actual_effect'],\n                milestone_completion=impl_row['milestone_completion'],\n                risk_score=impl_row['risk_score']\n            )\n            \n            # Get recent measurements\n            measurements_df = pd.read_sql(\n                \"\"\"\n                SELECT * FROM measurements \n                WHERE implementation_id = ? \n                ORDER BY measurement_date DESC \n                LIMIT 10\n                \"\"\",\n                conn, params=(implementation_id,)\n            )\n            \n            measurements = []\n            for _, row in measurements_df.iterrows():\n                measurements.append(ProductivityMeasurement(\n                    measurement_id=row['measurement_id'],\n                    firm_id=row['firm_id'],\n                    implementation_id=row['implementation_id'],\n                    measurement_date=datetime.fromisoformat(row['measurement_date']),\n                    productivity_growth=row['productivity_growth'],\n                    cost_savings=row['cost_savings'],\n                    revenue_increase=row['revenue_increase'],\n                    innovation_metrics=row['innovation_metrics'],\n                    confidence_interval=(row['confidence_lower'], row['confidence_upper'])\n                ))\n            \n            # Calculate risk score\n            risk_score = self.calculate_risk_score(implementation, measurements)\n            \n            # Update risk score in database\n            cursor = conn.cursor()\n            cursor.execute(\n                \"UPDATE implementations SET risk_score = ? WHERE implementation_id = ?\",\n                (risk_score, implementation_id)\n            )\n            \n            # Generate alerts\n            implementation.risk_score = risk_score\n            alerts = self.generate_alerts(firm_id, implementation, measurements)\n            \n            # Save alerts to database\n            for alert in alerts:\n                cursor.execute(\"\"\"\n                    INSERT INTO alerts (alert_id, firm_id, implementation_id, alert_type, \n                                      severity, message, created_at)\n                    VALUES (?, ?, ?, ?, ?, ?, ?)\n                \"\"\", (\n                    alert.alert_id, alert.firm_id, alert.implementation_id,\n                    alert.alert_type, alert.severity, alert.message, alert.created_at\n                ))\n            \n            conn.commit()\n            \n            if alerts:\n                logger.info(f\"Generated {len(alerts)} alerts for implementation {implementation_id}\")\n                \n        except Exception as e:\n            logger.error(f\"Error checking alerts for {implementation_id}: {e}\")\n        finally:\n            conn.close()\n    \n    async def start_background_monitoring(self):\n        \"\"\"Start background task for continuous monitoring\"\"\"\n        while True:\n            try:\n                # Check all active implementations\n                conn = sqlite3.connect(self.db_path)\n                cursor = conn.cursor()\n                \n                cursor.execute(\"\"\"\n                    SELECT firm_id, implementation_id \n                    FROM implementations \n                    WHERE stage != 'maintenance'\n                \"\"\")\n                \n                active_implementations = cursor.fetchall()\n                conn.close()\n                \n                # Process each implementation\n                for firm_id, impl_id in active_implementations:\n                    await self.check_and_generate_alerts(firm_id, impl_id)\n                \n                logger.info(f\"Completed monitoring check for {len(active_implementations)} implementations\")\n                \n            except Exception as e:\n                logger.error(f\"Background monitoring error: {e}\")\n            \n            # Wait 1 hour before next check\n            await asyncio.sleep(3600)\n    \n    def run_server(self, host: str = \"0.0.0.0\", port: int = 8000):\n        \"\"\"Run the monitoring server\"\"\"\n        logger.info(f\"Starting AI Implementation Monitoring System on {host}:{port}\")\n        \n        # Start background monitoring\n        asyncio.create_task(self.start_background_monitoring())\n        \n        # Run the FastAPI server\n        uvicorn.run(self.app, host=host, port=port)\n\n# Example usage and testing\nif __name__ == \"__main__\":\n    # Initialize monitoring system\n    monitor = RealTimeMonitoringSystem()\n    \n    # Example: Add test data\n    async def setup_test_data():\n        # This would typically be called via API endpoints\n        pass\n    \n    # Run the server\n    monitor.run_server()\n\n\"\"\"\nUsage Instructions:\n\n1. Install dependencies:\n   pip install fastapi uvicorn pandas numpy aiohttp\n\n2. Run the monitoring system:\n   python real_time_monitoring.py\n\n3. Access endpoints:\n   - http://localhost:8000/ - API root\n   - http://localhost:8000/health - Health check\n   - http://localhost:8000/dashboard/global - Global metrics\n   - POST http://localhost:8000/firms - Add new firm\n   - POST http://localhost:8000/implementations - Start tracking implementation\n   - POST http://localhost:8000/measurements - Record productivity measurement\n\n4. Integration with existing dashboards:\n   - Use API endpoints to feed data to web dashboards\n   - Real-time updates via WebSocket (can be added)\n   - Export data for further analysis\n\nFeatures:\n- Real-time productivity tracking\n- Mechanism-specific effect prediction\n- Early warning alert system\n- Risk score calculation\n- Background monitoring\n- RESTful API for integration\n- SQLite database for persistence\n- CORS support for web dashboards\n\"\"\""